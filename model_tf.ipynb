{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.transformations import ExtendedTransformation\n",
    "from utils.filters import SimpleFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/preprocessed/train_data.csv\")\n",
    "X_train, y_train = df_train.drop(columns=['Price']), df_train[['Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ExtendedTransformation()\n",
    "filter = SimpleFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (20974, 40)\n",
      "bin_vars_columns shape:  (36,)\n",
      "low_card_columns shape:  37\n"
     ]
    }
   ],
   "source": [
    "preprocessor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (20974, 40)\n",
      "X_low_card   shape:  (20974, 113)\n",
      "X_high_card shape:  (20974, 50)\n",
      "X_crossed_features shape:  (20974, 6670)\n",
      "X_EXPANDED shape:  (20974, 6835)\n"
     ]
    }
   ],
   "source": [
    "X_t, y_t = preprocessor.transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20974, 6835)\n",
      "(20974, 4173)\n",
      "(20974, 3193)\n",
      "(20974, 1635)\n"
     ]
    }
   ],
   "source": [
    "filter.fit(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20974, 4173)\n",
      "(20974, 3193)\n",
      "(20974, 1635)\n"
     ]
    }
   ],
   "source": [
    "X_f, y_f = filter.transform(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmartin/opt/anaconda3/envs/modelizacion_datos/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(800, activation='relu', input_shape=(X_f.shape[1],)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(400, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3868\n",
      "Epoch 2/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3925\n",
      "Epoch 3/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3915\n",
      "Epoch 4/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3883\n",
      "Epoch 5/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3811\n",
      "Epoch 6/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3858\n",
      "Epoch 7/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3823\n",
      "Epoch 8/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3933\n",
      "Epoch 9/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3962\n",
      "Epoch 10/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3851\n",
      "Epoch 11/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3796\n",
      "Epoch 12/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3896\n",
      "Epoch 13/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3874\n",
      "Epoch 14/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3929\n",
      "Epoch 15/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3926\n",
      "Epoch 16/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3807\n",
      "Epoch 17/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3809\n",
      "Epoch 18/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3919\n",
      "Epoch 19/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3874\n",
      "Epoch 20/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3747\n",
      "Epoch 21/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3796\n",
      "Epoch 22/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3811\n",
      "Epoch 23/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3806\n",
      "Epoch 24/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3692\n",
      "Epoch 25/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3695\n",
      "Epoch 26/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3768\n",
      "Epoch 27/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3657\n",
      "Epoch 28/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3806\n",
      "Epoch 29/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3818\n",
      "Epoch 30/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3633\n",
      "Epoch 31/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3686\n",
      "Epoch 32/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3801\n",
      "Epoch 33/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3723\n",
      "Epoch 34/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3642\n",
      "Epoch 35/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3718\n",
      "Epoch 36/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3723\n",
      "Epoch 37/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3743\n",
      "Epoch 38/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3693\n",
      "Epoch 39/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3587\n",
      "Epoch 40/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3743\n",
      "Epoch 41/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3708\n",
      "Epoch 42/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3722\n",
      "Epoch 43/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3669\n",
      "Epoch 44/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3749\n",
      "Epoch 45/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3668\n",
      "Epoch 46/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3607\n",
      "Epoch 47/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3773\n",
      "Epoch 48/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3763\n",
      "Epoch 49/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3597\n",
      "Epoch 50/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3613\n",
      "Epoch 51/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3627\n",
      "Epoch 52/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3775\n",
      "Epoch 53/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3706\n",
      "Epoch 54/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3712\n",
      "Epoch 55/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3641\n",
      "Epoch 56/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3559\n",
      "Epoch 57/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3657\n",
      "Epoch 58/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3643\n",
      "Epoch 59/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3574\n",
      "Epoch 60/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3706\n",
      "Epoch 61/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3580\n",
      "Epoch 62/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3557\n",
      "Epoch 63/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3587\n",
      "Epoch 64/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3612\n",
      "Epoch 65/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3577\n",
      "Epoch 66/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3565\n",
      "Epoch 67/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3608\n",
      "Epoch 68/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3603\n",
      "Epoch 69/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3640\n",
      "Epoch 70/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3596\n",
      "Epoch 71/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3682\n",
      "Epoch 72/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3639\n",
      "Epoch 73/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3497\n",
      "Epoch 74/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3510\n",
      "Epoch 75/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3622\n",
      "Epoch 76/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3625\n",
      "Epoch 77/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3471\n",
      "Epoch 78/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3645\n",
      "Epoch 79/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3604\n",
      "Epoch 80/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3558\n",
      "Epoch 81/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3628\n",
      "Epoch 82/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3582\n",
      "Epoch 83/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3541\n",
      "Epoch 84/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3515\n",
      "Epoch 85/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3577\n",
      "Epoch 86/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3557\n",
      "Epoch 87/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3598\n",
      "Epoch 88/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3621\n",
      "Epoch 89/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3505\n",
      "Epoch 90/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3573\n",
      "Epoch 91/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3466\n",
      "Epoch 92/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3604\n",
      "Epoch 93/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3615\n",
      "Epoch 94/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3486\n",
      "Epoch 95/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3555\n",
      "Epoch 96/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3617\n",
      "Epoch 97/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3478\n",
      "Epoch 98/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3507\n",
      "Epoch 99/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3532\n",
      "Epoch 100/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3531\n",
      "Epoch 101/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3615\n",
      "Epoch 102/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3494\n",
      "Epoch 103/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3591\n",
      "Epoch 104/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3601\n",
      "Epoch 105/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3470\n",
      "Epoch 106/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3606\n",
      "Epoch 107/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3508\n",
      "Epoch 108/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3457\n",
      "Epoch 109/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3458\n",
      "Epoch 110/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3552\n",
      "Epoch 111/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3472\n",
      "Epoch 112/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3538\n",
      "Epoch 113/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3514\n",
      "Epoch 114/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3456\n",
      "Epoch 115/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3490\n",
      "Epoch 116/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3530\n",
      "Epoch 117/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3426\n",
      "Epoch 118/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3470\n",
      "Epoch 119/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3454\n",
      "Epoch 120/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3435\n",
      "Epoch 121/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3566\n",
      "Epoch 122/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3485\n",
      "Epoch 123/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3509\n",
      "Epoch 124/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3437\n",
      "Epoch 125/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3514\n",
      "Epoch 126/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3402\n",
      "Epoch 127/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3581\n",
      "Epoch 128/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3449\n",
      "Epoch 129/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3492\n",
      "Epoch 130/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3413\n",
      "Epoch 131/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3518\n",
      "Epoch 132/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3438\n",
      "Epoch 133/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3546\n",
      "Epoch 134/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3451\n",
      "Epoch 135/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3502\n",
      "Epoch 136/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3540\n",
      "Epoch 137/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3398\n",
      "Epoch 138/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3438\n",
      "Epoch 139/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3475\n",
      "Epoch 140/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3478\n",
      "Epoch 141/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3310\n",
      "Epoch 142/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3522\n",
      "Epoch 143/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3373\n",
      "Epoch 144/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3350\n",
      "Epoch 145/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3471\n",
      "Epoch 146/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3418\n",
      "Epoch 147/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3433\n",
      "Epoch 148/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3358\n",
      "Epoch 149/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.3467\n",
      "Epoch 150/150\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.3449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31efd59a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_f, y_f,epochs=150, batch_size=32, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/preprocessed/test_data.csv\")\n",
    "X_test, y_test = df_test.drop(columns=['Price']), df_test[['Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (8989, 40)\n",
      "X_low_card   shape:  (8989, 113)\n",
      "X_high_card shape:  (8989, 50)\n",
      "X_crossed_features shape:  (8989, 6670)\n",
      "X_EXPANDED shape:  (8989, 6835)\n",
      "(8989, 4173)\n",
      "(8989, 3193)\n",
      "(8989, 1635)\n"
     ]
    }
   ],
   "source": [
    "X_test_proccesed, y_test_proccessed = preprocessor.transform(X_test, y_test)\n",
    "X_test_filtered, y_test_filtered = filter.transform(X_test_proccesed, y_test_proccessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmartin/opt/anaconda3/envs/modelizacion_datos/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_hat_unscaled = preprocessor.inverse_transform(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ( root_mean_squared_error, \n",
    "                             mean_absolute_error, \n",
    "                             mean_absolute_percentage_error )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Metrics:\n",
      "\n",
      "Metric                    Value\n",
      "------------------------------\n",
      "RMSE (₹)          27,770,639.70\n",
      "MAE (₹)            6,659,093.49\n",
      "MAPE (%)                 44.86%\n",
      "\n",
      "Interpretation:\n",
      "- RMSE: The model's predictions are typically off by ₹27,770,639.70 on average\n",
      "- MAE: The average absolute error is ₹6,659,093.49\n",
      "- MAPE: The predictions are off by 44.9% on average\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test.values\n",
    "y_pred = y_hat_unscaled\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "# Format metrics with units and percentages\n",
    "metrics = {\n",
    "    \"RMSE (₹)\": f\"{rmse:,.2f}\",\n",
    "    \"MAE (₹)\": f\"{mae:,.2f}\",\n",
    "    \"MAPE (%)\": f\"{mape:.2%}\"\n",
    "}\n",
    "\n",
    "# Display metrics in a formatted table\n",
    "print(\"\\nModel Performance Metrics:\\n\")\n",
    "print(f\"{'Metric':<15} {'Value':>15}\")\n",
    "print(\"-\" * 30)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric:<15} {value:>15}\")\n",
    "\n",
    "# Add a summary interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"- RMSE: The model's predictions are typically off by ₹{rmse:,.2f} on average\")\n",
    "print(f\"- MAE: The average absolute error is ₹{mae:,.2f}\")\n",
    "print(f\"- MAPE: The predictions are off by {mape:.1%} on average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
